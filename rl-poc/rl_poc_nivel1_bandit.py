"""
POC N√çVEL 1: MULTI-ARMED BANDIT (Mais Simples)
===============================================

QUANDO USAR: Quando voc√™ tem poucas vari√°veis de decis√£o e quer
testar qual estrat√©gia funciona melhor SEM considerar o perfil do cliente.

EXEMPLO: Testar qual dos 5 templates de mensagem tem melhor convers√£o.

COMPLEXIDADE: ‚≠ê‚òÜ‚òÜ‚òÜ‚òÜ
TEMPO IMPLEMENTA√á√ÉO: 2-4 horas
DADOS NECESS√ÅRIOS: 100-500 tentativas por bra√ßo
"""

import numpy as np
import pandas as pd
from dataclasses import dataclass
from typing import List, Dict
import json


@dataclass
class BanditArm:
    """Representa uma estrat√©gia de cobran√ßa"""
    name: str
    total_pulls: int = 0
    total_reward: float = 0.0
    conversions: int = 0
    
    @property
    def win_rate(self) -> float:
        """Taxa de convers√£o"""
        return self.conversions / self.total_pulls if self.total_pulls > 0 else 0.0
    
    @property
    def average_reward(self) -> float:
        """Recompensa m√©dia"""
        return self.total_reward / self.total_pulls if self.total_pulls > 0 else 0.0


class EpsilonGreedyBandit:
    """
    Multi-Armed Bandit com estrat√©gia Epsilon-Greedy
    
    CONCEITO:
    - Com probabilidade (1-epsilon): Escolhe a melhor estrat√©gia conhecida (exploit)
    - Com probabilidade epsilon: Escolhe estrat√©gia aleat√≥ria (explore)
    
    PAR√ÇMETROS:
    - epsilon: Taxa de explora√ß√£o (0.1 = 10% explora, 90% explora melhor)
    - decay_rate: Quanto epsilon diminui ao longo do tempo
    """
    
    def __init__(self, strategies: List[str], epsilon: float = 0.1, decay_rate: float = 0.995):
        self.arms = {name: BanditArm(name) for name in strategies}
        self.epsilon = epsilon
        self.initial_epsilon = epsilon
        self.decay_rate = decay_rate
        self.total_pulls = 0
        self.history = []
        
    def select_strategy(self) -> str:
        """
        Seleciona qual estrat√©gia usar
        
        Returns:
            Nome da estrat√©gia selecionada
        """
        # Explora (aleat√≥rio) ou Explota (melhor)
        if np.random.random() < self.epsilon:
            # EXPLORE: Escolhe aleat√≥rio
            strategy = np.random.choice(list(self.arms.keys()))
            exploration = True
        else:
            # EXPLOIT: Escolhe a melhor
            strategy = max(self.arms.items(), key=lambda x: x[1].average_reward)[0]
            exploration = False
        
        self.total_pulls += 1
        
        # Log da decis√£o
        self.history.append({
            'pull': self.total_pulls,
            'strategy': strategy,
            'exploration': exploration,
            'epsilon': self.epsilon
        })
        
        return strategy
    
    def update(self, strategy: str, cliente_pagou: bool, valor_pago: float = 0.0):
        """
        Atualiza as estat√≠sticas ap√≥s receber feedback
        
        Args:
            strategy: Estrat√©gia que foi usada
            cliente_pagou: Se o cliente pagou ou n√£o
            valor_pago: Valor que o cliente pagou (opcional)
        """
        arm = self.arms[strategy]
        
        # Recompensa: 1 se pagou, 0 se n√£o pagou
        # Ou pode usar o valor_pago diretamente
        reward = 1.0 if cliente_pagou else 0.0
        # reward = valor_pago / 1000.0  # Normaliza valor para 0-1
        
        arm.total_pulls += 1
        arm.total_reward += reward
        if cliente_pagou:
            arm.conversions += 1
        
        # Decay do epsilon (explora menos com o tempo)
        self.epsilon = max(0.01, self.epsilon * self.decay_rate)
        
        # Log do resultado
        self.history[-1].update({
            'cliente_pagou': cliente_pagou,
            'valor_pago': valor_pago,
            'reward': reward,
            'arm_pulls': arm.total_pulls,
            'arm_win_rate': arm.win_rate
        })
    
    def get_best_strategy(self) -> str:
        """Retorna a estrat√©gia com melhor performance"""
        return max(self.arms.items(), key=lambda x: x[1].average_reward)[0]
    
    def get_stats(self) -> pd.DataFrame:
        """Retorna estat√≠sticas de todas as estrat√©gias"""
        data = []
        for name, arm in self.arms.items():
            data.append({
                'Estrat√©gia': name,
                'Tentativas': arm.total_pulls,
                'Convers√µes': arm.conversions,
                'Taxa Convers√£o': f"{arm.win_rate*100:.1f}%",
                'Reward M√©dio': f"{arm.average_reward:.3f}",
                'Reward Total': f"{arm.total_reward:.2f}"
            })
        return pd.DataFrame(data).sort_values('Reward M√©dio', ascending=False)
    
    def save_model(self, filepath: str):
        """Salva o modelo treinado"""
        model_data = {
            'epsilon': self.epsilon,
            'initial_epsilon': self.initial_epsilon,
            'decay_rate': self.decay_rate,
            'total_pulls': self.total_pulls,
            'arms': {
                name: {
                    'total_pulls': arm.total_pulls,
                    'total_reward': arm.total_reward,
                    'conversions': arm.conversions
                }
                for name, arm in self.arms.items()
            },
            'history': self.history
        }
        with open(filepath, 'w') as f:
            json.dump(model_data, f, indent=2)
        print(f"‚úÖ Modelo salvo em: {filepath}")


# =============================================================================
# EXEMPLO DE USO: Sistema de Cobran√ßa
# =============================================================================

def simular_cliente_responde(estrategia: str) -> tuple[bool, float]:
    """
    Simula se o cliente paga baseado na estrat√©gia
    
    Na vida real, isso viria do sistema de cobran√ßa
    Aqui simulamos com probabilidades diferentes por estrat√©gia
    """
    # Probabilidades reais de convers√£o por estrat√©gia (desconhecidas a priori)
    PROBABILIDADES = {
        'formal_rigido': 0.15,      # Estrat√©gia muito formal
        'emp√°tico_flex√≠vel': 0.32,   # Estrat√©gia emp√°tica (melhor)
        'agressivo': 0.08,           # Estrat√©gia agressiva (pior)
        'desconto_imediato': 0.28,   # Oferece desconto logo
        'parcelamento': 0.25         # Foca em parcelamento
    }
    
    # Valores m√©dios pagos quando converte
    VALORES_MEDIOS = {
        'formal_rigido': 500,
        'emp√°tico_flex√≠vel': 450,
        'agressivo': 400,
        'desconto_imediato': 350,  # Desconto reduz valor
        'parcelamento': 480
    }
    
    prob = PROBABILIDADES[estrategia]
    cliente_pagou = np.random.random() < prob
    
    if cliente_pagou:
        # Adiciona varia√ß√£o no valor pago
        valor_base = VALORES_MEDIOS[estrategia]
        valor_pago = valor_base * np.random.uniform(0.8, 1.2)
    else:
        valor_pago = 0.0
    
    return cliente_pagou, valor_pago


def main():
    """Executa a simula√ß√£o completa"""
    
    print("="*70)
    print("POC N√çVEL 1: MULTI-ARMED BANDIT - Sistema de Cobran√ßa Oramind")
    print("="*70)
    print()
    
    # Define as estrat√©gias dispon√≠veis
    estrategias = [
        'formal_rigido',
        'emp√°tico_flex√≠vel',
        'agressivo',
        'desconto_imediato',
        'parcelamento'
    ]
    
    # Inicializa o bandit
    bandit = EpsilonGreedyBandit(
        strategies=estrategias,
        epsilon=0.2,        # 20% de explora√ß√£o inicial
        decay_rate=0.995    # Decai lentamente
    )
    
    print(f"üìä Iniciando com {len(estrategias)} estrat√©gias")
    print(f"üîç Epsilon inicial: {bandit.epsilon} (taxa de explora√ß√£o)")
    print()
    
    # Simula 1000 tentativas de cobran√ßa
    NUM_TENTATIVAS = 1000
    
    print(f"üöÄ Simulando {NUM_TENTATIVAS} tentativas de cobran√ßa...")
    print()
    
    for i in range(NUM_TENTATIVAS):
        # 1. Bandit escolhe qual estrat√©gia usar
        estrategia_escolhida = bandit.select_strategy()
        
        # 2. Sistema executa a cobran√ßa com essa estrat√©gia
        cliente_pagou, valor_pago = simular_cliente_responde(estrategia_escolhida)
        
        # 3. Bandit aprende com o resultado
        bandit.update(estrategia_escolhida, cliente_pagou, valor_pago)
        
        # Mostra progresso a cada 100 tentativas
        if (i + 1) % 100 == 0:
            melhor = bandit.get_best_strategy()
            print(f"Tentativa {i+1:4d} | Melhor estrat√©gia at√© agora: {melhor} | Epsilon: {bandit.epsilon:.3f}")
    
    print()
    print("="*70)
    print("üìä RESULTADOS FINAIS")
    print("="*70)
    print()
    
    # Mostra estat√≠sticas
    stats = bandit.get_stats()
    print(stats.to_string(index=False))
    print()
    
    # Mostra a melhor estrat√©gia
    melhor_estrategia = bandit.get_best_strategy()
    print(f"üèÜ MELHOR ESTRAT√âGIA: {melhor_estrategia}")
    print()
    
    # Detalhes da melhor
    melhor_arm = bandit.arms[melhor_estrategia]
    print(f"   ‚Ä¢ Taxa de Convers√£o: {melhor_arm.win_rate*100:.1f}%")
    print(f"   ‚Ä¢ Tentativas: {melhor_arm.total_pulls}")
    print(f"   ‚Ä¢ Convers√µes: {melhor_arm.conversions}")
    print(f"   ‚Ä¢ Reward M√©dio: {melhor_arm.average_reward:.3f}")
    print()
    
    # Salva o modelo
    bandit.save_model('bandit_model.json')
    
    # An√°lise de explora√ß√£o vs exploita√ß√£o
    history_df = pd.DataFrame(bandit.history)
    exploration_rate = history_df['exploration'].mean()
    print(f"üìà Taxa de explora√ß√£o durante treinamento: {exploration_rate*100:.1f}%")
    print(f"üìà Epsilon final: {bandit.epsilon:.3f}")
    print()
    
    print("="*70)
    print("üí° PR√ìXIMOS PASSOS")
    print("="*70)
    print()
    print("1. Integre com seu sistema real de cobran√ßa")
    print("2. Substitua simular_cliente_responde() com dados reais")
    print("3. Ajuste epsilon e decay_rate baseado em dados reais")
    print("4. Adicione mais estrat√©gias conforme testar")
    print("5. Considere evoluir para Contextual Bandit (N√≠vel 2)")
    print()


if __name__ == "__main__":
    main()


# =============================================================================
# COMO USAR NO SISTEMA REAL
# =============================================================================

"""
INTEGRA√á√ÉO COM ORAMIND:

1. No Agente de Estrat√©gia:
   
   # Inicializa o bandit uma vez
   bandit = EpsilonGreedyBandit(strategies=ESTRATEGIAS_DISPONIVEIS)
   
   # Para cada novo cliente
   estrategia = bandit.select_strategy()
   
   # Usa a estrat√©gia selecionada
   mensagem = gerar_mensagem(cliente, estrategia)
   enviar_mensagem(cliente, mensagem)
   
   # Armazena: cliente_id, estrategia, timestamp

2. No Callback de Pagamento:
   
   # Quando cliente paga (ou n√£o paga ap√≥s X dias)
   bandit.update(
       strategy=estrategia_usada,
       cliente_pagou=True,
       valor_pago=500.00
   )
   
3. Persist√™ncia:
   
   # A cada 100 updates ou fim do dia
   bandit.save_model('models/bandit_latest.json')
   
   # Para carregar
   # TODO: Implementar load_model()

4. Monitoring:
   
   # Dashboard di√°rio
   stats = bandit.get_stats()
   enviar_para_dashboard(stats)
   
   # Alerta se alguma estrat√©gia est√° muito ruim
   if any(arm.win_rate < 0.05 for arm in bandit.arms.values()):
       alertar_time()
"""
